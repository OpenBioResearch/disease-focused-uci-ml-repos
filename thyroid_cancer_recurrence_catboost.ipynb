{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWWBaTvfbiSN"
      },
      "source": [
        "# Leveraging CatBoost to identify features in recurrence\n",
        "\n",
        "This notebook leverages CatBoost to analyze clinicopathologic features from a thyroid cancer dataset. The primary goal is to identify the most significant features influencing thyroid cancer recurrence. The notebook will leverage GPU whenever performance can be boosted.  A pdf findings summary will be provided.\n",
        "\n",
        "## UCI Dataset\n",
        "\n",
        "Dataset: [UCI Machine Learning Repository - Differentiated Thyroid Cancer Recurrence Dataset](https://archive.ics.uci.edu/dataset/915/differentiated+thyroid+cancer+recurrence)\n",
        "\n",
        "Citation: Borzooei,Shiva and Tarokhian,Aidin. (2023). Differentiated Thyroid Cancer Recurrence. UCI Machine Learning Repository. https://doi.org/10.24432/C5632J.\n",
        "\n",
        "## Google colab\n",
        "\n",
        "You may run this notebook on Google Colab by clicking the \"Open in Colab\" badge below:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/OpenBioResearch/disease-focused-uci-ml-repos/blob/main/thyroid_cancer_recurrence_catboost.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4Vlo07JYf2o"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6eMXIRDch-U"
      },
      "outputs": [],
      "source": [
        "# Install ucimlrepo package\n",
        "\n",
        "!pip install ucimlrepo\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Fetch dataset from UCI ML Repository\n",
        "differentiated_thyroid_cancer_recurrence = fetch_ucirepo(id=915)\n",
        "\n",
        "# Data (as pandas dataframes)\n",
        "X = differentiated_thyroid_cancer_recurrence.data.features\n",
        "y = differentiated_thyroid_cancer_recurrence.data.targets\n",
        "\n",
        "print(differentiated_thyroid_cancer_recurrence.metadata)\n",
        "print(differentiated_thyroid_cancer_recurrence.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTZUt2k1s78u"
      },
      "outputs": [],
      "source": [
        "# Features and target dataframe\n",
        "\n",
        "print(\"Features dataframe (X):\")\n",
        "display(X.head())\n",
        "\n",
        "print(\"Target dataframe (y):\")\n",
        "display(y.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh6T2DSDtDZm"
      },
      "outputs": [],
      "source": [
        "# splits the data into training and testing sets.\n",
        "\n",
        "missing_values_X = X.isnull().sum()\n",
        "missing_values_y = y.isnull().sum()\n",
        "print(\"Missing values in features (X):\\n\", missing_values_X)\n",
        "print(\"Missing values in target (y):\\n\", missing_values_y)\n",
        "\n",
        "for column in X.columns:\n",
        "    if X[column].dtype == 'object':\n",
        "        X[column].fillna(X[column].mode()[0], inplace=True)\n",
        "    else:\n",
        "        X[column].fillna(X[column].median(), inplace=True)\n",
        "\n",
        "# Encode categorical features using one-hot encoding\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"-------------------\")\n",
        "print(\"Data Split Summary:\")\n",
        "print(f\"Training Set: {len(X_train)} samples\")\n",
        "print(f\"Testing Set: {len(X_test)} samples\")\n",
        "print(\"-------------------\")\n",
        "print(\"Data preprocessing complete. Ready for modeling.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXxawGnkwde7"
      },
      "outputs": [],
      "source": [
        "# Model Training with CatBoost\n",
        "!pip install catboost\n",
        "!pip install ipywidgets\n",
        "\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize the CatBoostClassifier\n",
        "model = CatBoostClassifier(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.1,\n",
        "    depth=6\n",
        ")\n",
        "\n",
        "# Prepare the Pool data structure for CatBoost\n",
        "train_pool = Pool(X_train, y_train)\n",
        "test_pool = Pool(X_test, y_test)\n",
        "\n",
        "# Train the model with a progress indicator\n",
        "model.fit(train_pool, eval_set=test_pool, verbose=100, plot=True)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{report}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt7yMoa1DHac"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def generate_feature_importance_report(model, X_train):\n",
        "    # Get feature importances\n",
        "    feature_importances = model.get_feature_importance(Pool(X_train, y_train))\n",
        "    feature_names = X_train.columns\n",
        "\n",
        "    # Create a DataFrame for feature importances\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': feature_importances\n",
        "    }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    display(importance_df)\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
        "    plt.xlabel(\"Feature Importance\")\n",
        "    plt.title(\"Detailed Feature Importance Analysis\")\n",
        "    plt.gca().invert_yaxis()  # Invert y-axis to show the most important feature at the top\n",
        "    plt.show()\n",
        "\n",
        "    return importance_df\n",
        "\n",
        "# Generate the feature importance report\n",
        "importance_df = generate_feature_importance_report(model, X_train)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.histplot(y_pred_proba, bins=30, kde=True)\n",
        "plt.xlabel('Predicted Probability of Recurrence')\n",
        "plt.title('Distribution of Predicted Probabilities')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VYR7lWzjdUJ"
      },
      "outputs": [],
      "source": [
        "# Administrative Summary\n",
        "\n",
        "!pip install fpdf\n",
        "from fpdf import FPDF\n",
        "from datetime import date\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, 'Thyroid Cancer Recurrence Machine Learning - UCI dataset', 0, 1, 'C')\n",
        "        self.set_font('Arial', '', 10)\n",
        "        today = date.today().strftime('%B %d, %Y')\n",
        "        self.cell(0, 10, f'Date: {today}', 0, 1, 'C')\n",
        "        self.ln(10)\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Arial', 'B', 12)\n",
        "        self.cell(0, 10, title, 0, 1, 'L')\n",
        "        self.ln(10)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font('Arial', '', 12)\n",
        "        self.multi_cell(0, 10, body)\n",
        "        self.ln()\n",
        "\n",
        "# Generate classification report\n",
        "classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Create instance of FPDF class\n",
        "pdf = PDF()\n",
        "\n",
        "# Add a page\n",
        "pdf.add_page()\n",
        "\n",
        "# Set title\n",
        "pdf.chapter_title('Model Performance Metrics')\n",
        "\n",
        "# Add model accuracy\n",
        "pdf.multi_cell(0, 10, txt=f\"The model achieved an accuracy of {accuracy*100:.2f}%. This indicates how well the model can predict whether thyroid cancer will recur.\", align=\"L\")\n",
        "\n",
        "# Format and add classification report\n",
        "pdf.chapter_title('Classification Report')\n",
        "pdf.set_font('Arial', 'B', 10)\n",
        "pdf.cell(40, 10, 'Class', 1)\n",
        "pdf.cell(30, 10, 'Precision', 1)\n",
        "pdf.cell(30, 10, 'Recall', 1)\n",
        "pdf.cell(30, 10, 'F1-Score', 1)\n",
        "pdf.cell(30, 10, 'Support', 1)\n",
        "pdf.ln()\n",
        "\n",
        "pdf.set_font('Arial', '', 10)\n",
        "for label, metrics in classification_rep.items():\n",
        "    if isinstance(metrics, dict):\n",
        "        pdf.cell(40, 10, label, 1)\n",
        "        pdf.cell(30, 10, f\"{metrics['precision']:.2f}\", 1)\n",
        "        pdf.cell(30, 10, f\"{metrics['recall']:.2f}\", 1)\n",
        "        pdf.cell(30, 10, f\"{metrics['f1-score']:.2f}\", 1)\n",
        "        pdf.cell(30, 10, f\"{metrics['support']}\", 1)\n",
        "        pdf.ln()\n",
        "\n",
        "# Add precision explanation and value\n",
        "precision_text = f\"Precision measures how many of the positive predictions made by the model are actually correct. For 'No' recurrence, the precision is 0.98, and for 'Yes' recurrence, the precision is 0.95. These values signify that out of all the positive predictions made by the model, 0.98 for 'No' and 0.95 for 'Yes' were correct, highlighting the model's ability to accurately identify true positives.\"\n",
        "pdf.chapter_body(precision_text)\n",
        "\n",
        "# Add recall explanation and value\n",
        "recall_text = f\"Recall indicates how many of the actual positive cases were correctly identified by the model. For 'No' recurrence, the recall is 0.98, and for 'Yes' recurrence, the recall is 0.95. This means that the model was able to identify 0.98 of all the actual 'No' cases and 0.95 of all the actual 'Yes' cases, demonstrating its effectiveness in capturing true positives.\"\n",
        "pdf.chapter_body(recall_text)\n",
        "\n",
        "# Add F1-score explanation and value\n",
        "f1_text = f\"The F1 score is the harmonic mean of precision and recall, providing a single metric to evaluate the model's performance. For 'No' recurrence, the F1 score is 0.98, and for 'Yes' recurrence, the F1 score is 0.95. These scores reflect the balance between precision and recall, indicating the model's overall accuracy in predicting positive cases.\"\n",
        "pdf.chapter_body(f1_text)\n",
        "\n",
        "# Get feature importance from the model\n",
        "feature_importances = model.get_feature_importance()\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Create a dataframe for feature importance\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "feature_importance_df = feature_importance_df[feature_importance_df['Feature'] != 'Age']\n",
        "\n",
        "# Filter out features with importance score of 0\n",
        "feature_importance_df = feature_importance_df[feature_importance_df['Importance'] > 0]\n",
        "\n",
        "# Get top 5 and bottom 5 features\n",
        "top_5_features = feature_importance_df.head(5)\n",
        "bottom_5_features = feature_importance_df.tail(5)\n",
        "\n",
        "# Generate feature importance explanations dynamically\n",
        "def get_importance_explanation(importance):\n",
        "    if importance > 10:\n",
        "        return \"This feature has a high importance score, suggesting a significant role in predicting recurrence.\"\n",
        "    elif importance > 5:\n",
        "        return \"This feature has a moderate importance score, indicating some influence on predicting recurrence.\"\n",
        "    else:\n",
        "        return \"This feature has a low importance score, indicating limited influence on predicting recurrence.\"\n",
        "\n",
        "# Add top 5 and bottom 5 feature importance explanations to the PDF\n",
        "pdf.chapter_title('Top 5 Most Important Features')\n",
        "for index, row in top_5_features.iterrows():\n",
        "    explanation = f\"- {row['Feature']}: {get_importance_explanation(row['Importance'])}\"\n",
        "    pdf.chapter_body(explanation)\n",
        "\n",
        "pdf.chapter_title('Bottom 5 Least Important Features')\n",
        "for index, row in bottom_5_features.iterrows():\n",
        "    explanation = f\"- {row['Feature']}: {get_importance_explanation(row['Importance'])}\"\n",
        "    pdf.chapter_body(explanation)\n",
        "\n",
        "# Visualize the feature importance\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
        "plt.title('Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "\n",
        "# Adjust the margins to make sure all words are displayed\n",
        "plt.gcf().subplots_adjust(left=0.35)  # Increased the left margin\n",
        "\n",
        "# Use tight layout to automatically adjust\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"feature_importance.png\")\n",
        "pdf.image(\"feature_importance.png\", w=150)\n",
        "plt.close()\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig(\"confusion_matrix.png\")\n",
        "pdf.image(\"confusion_matrix.png\", w=150)\n",
        "pdf.multi_cell(0, 10, txt=\"This confusion matrix illustrates the model's performance by showing the number of true positives, true negatives, false positives, and false negatives. The high values along the diagonal indicate that the model is accurately predicting both recurrence and non-recurrence cases, with minimal errors.\", align=\"L\")\n",
        "plt.close()\n",
        "\n",
        "# Distribution of Predicted Probabilities\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.histplot(y_pred_proba, bins=30, kde=True)\n",
        "plt.xlabel('Predicted Probability of Recurrence')\n",
        "plt.title('Distribution of Predicted Probabilities')\n",
        "plt.savefig(\"predicted_probabilities.png\")\n",
        "pdf.image(\"predicted_probabilities.png\", w=150)\n",
        "pdf.multi_cell(0, 10, txt=\"The distribution of predicted probabilities shows how confident the model is in its predictions. A higher peak towards the right indicates greater confidence in predicting recurrence. This is significant as it suggests that the model is not only accurate but also confident in its predictions, which is crucial for clinical decision-making regarding recurrent thyroid cancer.\", align=\"L\")\n",
        "plt.close()\n",
        "\n",
        "# Save the PDF with the original path\n",
        "pdf.output(\"executive_thyroid_recurrence.pdf\")\n",
        "\n",
        "print(\"Executive summary PDF generated and saved to executive_summary.pdf\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN+Aer1n0WlhlqfIEeSrmzx",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
