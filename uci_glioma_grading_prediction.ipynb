{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGaN9vFLyrWt"
      },
      "source": [
        "# Predicting glioma grading of LGG or GBM using clinical, molecular and mutation features\n",
        "\n",
        "This jupyter notebook predicts features affecting glioma grading using a Random Forest model, and then trains and evaluates multiple classification models (Logistic Regression, Random Forest, SVM) to predict glioma grade (LGG or GBM).  A summary of findings and insights in pdf format is generated.\n",
        "\n",
        "## Google colab\n",
        "\n",
        "You may run this notebook on Google Colab by clicking the \"Open in Colab\" badge below:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/OpenBioResearch/disease-focused-uci-ml-repos/blob/main/uci_glioma_grading_prediction.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOiM1i_9Ixv0"
      },
      "outputs": [],
      "source": [
        "# Install the ucimlrepo library to fetch the glioma dataset\n",
        "%pip install ucimlrepo\n",
        "\n",
        "# Fetch the glioma dataset from the UCI Machine Learning Repository\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "glioma_grading_clinical_and_mutation_features = fetch_ucirepo(id=759)\n",
        "\n",
        "X = glioma_grading_clinical_and_mutation_features.data.features\n",
        "y = glioma_grading_clinical_and_mutation_features.data.targets\n",
        "\n",
        "print(glioma_grading_clinical_and_mutation_features.metadata)\n",
        "print(glioma_grading_clinical_and_mutation_features.variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2Er4qPGqDWj"
      },
      "outputs": [],
      "source": [
        "# Explore the dataset to understand its structure and content\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Features:\")\n",
        "print(X.head())\n",
        "\n",
        "print(\"\\nTargets:\")\n",
        "print(y.head())\n",
        "\n",
        "print(\"\\nMissing values in features:\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in targets:\")\n",
        "print(y.isnull().sum())\n",
        "\n",
        "for column in X.select_dtypes(include=['number']).columns:\n",
        "    X[column].fillna(X[column].mean(), inplace=True)\n",
        "\n",
        "# Replace missing values in non-numeric columns with the mode of the column\n",
        "for column in X.select_dtypes(exclude=['number']).columns:\n",
        "    X[column].fillna(X[column].mode()[0], inplace=True)\n",
        "\n",
        "# Handle missing values in the target variable 'y' if it's numeric\n",
        "if y.dtypes['Grade'] in ['int64', 'float64']:\n",
        "    y.fillna(y.mean(), inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WJ8BB-nqKce"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set shape (features): {X_train.shape}\")\n",
        "print(f\"Training set shape (target): {y_train.shape}\")\n",
        "print(f\"Testing set shape (features): {X_test.shape}\")\n",
        "print(f\"Testing set shape (target): {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDB50csZsi6L"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Encode categorical features\n",
        "for column in X_train.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    X_train[column] = le.fit_transform(X_train[column])\n",
        "    X_test[column] = le.transform(X_test[column])\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "selected_features = X_train.columns[indices][:20]\n",
        "print(\"Top 20 selected features:\")\n",
        "print(selected_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_75jZjIos9ae"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train[selected_features], y_train.values.ravel())\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test[selected_features])\n",
        "    y_prob = model.predict_proba(X_test[selected_features])[:, 1]\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    print(f'=== {name} ===')\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'ROC-AUC: {roc_auc}')\n",
        "    print('Classification Report:')\n",
        "    print(report)\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F  # Add this import\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train[selected_features].values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values.ravel(), dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test[selected_features].values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values.ravel(), dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the neural network architecture with regularization\n",
        "class RegularizedNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(RegularizedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 64)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer with 50% probability\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = RegularizedNN(input_size=len(selected_features))\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # Adding weight decay\n",
        "\n",
        "# Training loop with early stopping\n",
        "num_epochs = 50\n",
        "best_val_loss = float('inf')\n",
        "patience, trials = 5, 0\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "    val_loss = 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(test_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_losses[-1]}, Validation Loss: {val_loss}')\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        trials = 0\n",
        "    else:\n",
        "        trials += 1\n",
        "\n",
        "    if trials >= patience:\n",
        "        print(f'Early stopping on epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    predictions = (outputs.numpy().squeeze() > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    roc_auc = roc_auc_score(y_test, outputs.numpy().squeeze())\n",
        "    report = classification_report(y_test, predictions)\n",
        "\n",
        "    print('=== Neural Network ===')\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print(f'ROC-AUC: {roc_auc}')\n",
        "    print('Classification Report:')\n",
        "    print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  \n",
        "\n",
        "# Assuming train_losses and val_losses are lists containing loss values for each epoch\n",
        "def plot_loss(train_losses, val_losses):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_loss(train_losses, val_losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-Aa8nL_uPZi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate and plot feature importance\n",
        "def plot_feature_importance(model, feature_names):\n",
        "    # Extract the weights from the first fully connected layer\n",
        "    fc1_weights = model.fc1.weight.cpu().detach().numpy()\n",
        "\n",
        "    feature_importance = np.sum(np.abs(fc1_weights), axis=0)\n",
        "    feature_importance = feature_importance / np.sum(feature_importance)\n",
        "\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': feature_importance\n",
        "    })\n",
        "\n",
        "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(importance_df['Feature'], importance_df['Importance'])\n",
        "    plt.xlabel('Features')\n",
        "    plt.ylabel('Importance')\n",
        "    plt.title('Feature Importance')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.show()\n",
        "\n",
        "feature_names = X_train[selected_features].columns\n",
        "plot_feature_importance(model, feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcYtMtYIvJl0"
      },
      "outputs": [],
      "source": [
        "!pip install fpdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urhRJBpMRKZy"
      },
      "outputs": [],
      "source": [
        "from fpdf import FPDF\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "output_dir = \"output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def save_plot_as_image(fig, filename):\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    fig.savefig(filepath, format='png')\n",
        "    print(f\"Saved plot to {filepath}\")\n",
        "    plt.close(fig)\n",
        "\n",
        "def remove_non_ascii(text):\n",
        "    return ''.join(i for i in text if ord(i) < 128)\n",
        "\n",
        "pdf = FPDF()\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", 'B', 16)\n",
        "pdf.cell(200, 10, \"Glioma Grading Clinical and Mutation Features\", ln=True, align='C')\n",
        "pdf.set_font(\"Arial\", 'I', 12)\n",
        "pdf.cell(200, 10, datetime.now().strftime(\"Date: %Y-%m-%d\"), ln=True, align='C')\n",
        "pdf.ln(10)\n",
        "pdf.set_font(\"Arial\", 'B', 14)\n",
        "pdf.cell(200, 10, \"Overview\", ln=True, align='C')\n",
        "pdf.ln(10)\n",
        "pdf.set_font(\"Arial\", '', 12)\n",
        "overview_text = \"\"\"\n",
        "This report summarizes the analysis and modeling efforts undertaken to classify glioma types into Lower-Grade Glioma (LGG) and Glioblastoma Multiforme (GBM). We utilized several machine learning models, including Logistic Regression, Random Forest, Support Vector Machine (SVM), and a Neural Network implemented in PyTorch. Early stopping was employed to monitor and prevent overfitting during the training of the neural network model.\n",
        "\n",
        "The Random Forest model was chosen for its ability to handle a large number of features and its capability to provide feature importance scores, which help in identifying the most influential features for glioma grading. The SVM and Logistic Regression models were used for their robustness and interpretability, while the neural network was employed to capture complex patterns in the data.\n",
        "\"\"\"\n",
        "pdf.multi_cell(0, 10, overview_text)\n",
        "\n",
        "# Add explanation of metrics and findings\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", 'B', 14)\n",
        "pdf.cell(200, 10, \"Evaluation Metrics and Findings\", ln=True, align='C')\n",
        "pdf.ln(10)\n",
        "pdf.set_font(\"Arial\", '', 12)\n",
        "metrics_explanation = \"\"\"\n",
        "The following metrics are used to evaluate the performance of the models:\n",
        "\n",
        "- Accuracy: The proportion of correctly classified instances among all instances. An accuracy close to 1.0 indicates a high level of correctness in the model's predictions.\n",
        "- ROC-AUC: The area under the Receiver Operating Characteristic curve, indicating the model's ability to discriminate between classes. A higher ROC-AUC score indicates better performance.\n",
        "- Classification Report: Includes precision, recall, and F1-score for each class. Precision is the ratio of true positive predictions to the total predicted positives, recall is the ratio of true positives to the total actual positives, and the F1-score is the harmonic mean of precision and recall.\n",
        "\n",
        "Findings:\n",
        "- The models generally achieved high accuracy, indicating good performance in classifying glioma types.\n",
        "- The ROC-AUC scores were also high, suggesting that the models are effective in distinguishing between LGG and GBM.\n",
        "- The classification reports provide a detailed breakdown of the performance for each class, showing high precision and recall for both LGG and GBM.\n",
        "\"\"\"\n",
        "pdf.multi_cell(0, 10, metrics_explanation)\n",
        "\n",
        "# Add metrics for Logistic Regression, Random Forest, SVM, and Neural Network\n",
        "metrics_summary = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train[selected_features], y_train.values.ravel())\n",
        "    y_pred = model.predict(X_test[selected_features])\n",
        "    y_prob = model.predict_proba(X_test[selected_features])[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    metrics_summary.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'Precision (LGG)': report['0']['precision'],\n",
        "        'Recall (LGG)': report['0']['recall'],\n",
        "        'F1-Score (LGG)': report['0']['f1-score'],\n",
        "        'Precision (GBM)': report['1']['precision'],\n",
        "        'Recall (GBM)': report['1']['recall'],\n",
        "        'F1-Score (GBM)': report['1']['f1-score']\n",
        "    })\n",
        "\n",
        "pdf.set_font(\"Arial\", 'B', 12)\n",
        "pdf.cell(200, 10, \"Metrics Summary Table\", ln=True, align='C')\n",
        "pdf.ln(10)\n",
        "pdf.set_font(\"Arial\", '', 12)\n",
        "\n",
        "lgg_metrics = [[\"Model\", \"Accuracy\", \"ROC-AUC\", \"Precision\", \"Recall\", \"F1-Score\"]]\n",
        "gbm_metrics = [[\"Model\", \"Accuracy\", \"ROC-AUC\", \"Precision\", \"Recall\", \"F1-Score\"]]\n",
        "\n",
        "for metric in metrics_summary:\n",
        "    lgg_metrics.append([metric['Model'], f\"{metric['Accuracy']:.4f}\", f\"{metric['ROC-AUC']:.4f}\", f\"{metric['Precision (LGG)']:.4f}\", f\"{metric['Recall (LGG)']:.4f}\", f\"{metric['F1-Score (LGG)']:.4f}\"])\n",
        "    gbm_metrics.append([metric['Model'], f\"{metric['Accuracy']:.4f}\", f\"{metric['ROC-AUC']:.4f}\", f\"{metric['Precision (GBM)']:.4f}\", f\"{metric['Recall (GBM)']:.4f}\", f\"{metric['F1-Score (GBM)']:.4f}\"])\n",
        "\n",
        "def add_table(pdf, table_data, title):\n",
        "    pdf.set_font(\"Arial\", 'B', 14)\n",
        "    pdf.cell(200, 10, title, ln=True, align='C')\n",
        "    pdf.ln(5)\n",
        "    pdf.set_font(\"Arial\", 'B', 12)\n",
        "    col_width = pdf.w / (len(table_data[0]) + 1)\n",
        "    row_height = pdf.font_size * 1.5\n",
        "    for row in table_data:\n",
        "        for cell in row:\n",
        "            pdf.cell(col_width, row_height, str(cell), border=1, align='C')\n",
        "        pdf.ln(row_height)\n",
        "    pdf.ln(10)\n",
        "\n",
        "add_table(pdf, lgg_metrics, \"LGG Metrics\")\n",
        "add_table(pdf, gbm_metrics, \"GBM Metrics\")\n",
        "\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", 'B', 14)\n",
        "pdf.cell(200, 10, \"Feature Importance (Random Forest)\", ln=True, align='C')\n",
        "pdf.ln(10)\n",
        "pdf.set_font(\"Arial\", '', 12)\n",
        "pdf.multi_cell(0, 10, \"The following plot shows the importance of each feature as determined by the Random Forest model. Higher values indicate greater importance in determining glioma grading.\")\n",
        "\n",
        "# Train a Random Forest model to get feature importances\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train[selected_features], y_train.values.ravel())\n",
        "rf_importances = rf_model.feature_importances_\n",
        "rf_indices = np.argsort(rf_importances)[::-1]\n",
        "rf_selected_features = X_train.columns[rf_indices][:20]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.bar(rf_selected_features, rf_importances[rf_indices][:20])\n",
        "ax.set_xlabel('Features')\n",
        "ax.set_ylabel('Importance')\n",
        "ax.set_title('Feature Importance (Random Forest)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "save_plot_as_image(fig, \"rf_feature_importance.png\")\n",
        "pdf.image(os.path.join(output_dir, \"rf_feature_importance.png\"), x=None, y=None, w=190, h=100)\n",
        "\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", 'B', 14)\n",
        "pdf.cell(200, 10, \"Training and Validation Loss\", ln=True, align='C')\n",
        "pdf.ln(10)\n",
        "pdf.set_font(\"Arial\", '', 12)\n",
        "pdf.multi_cell(0, 10, \"The following plot shows the training and validation loss over the epochs for the neural network. Monitoring these losses helps in preventing overfitting through early stopping.\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.plot(train_losses, label='Training Loss')\n",
        "ax.plot(val_losses, label='Validation Loss')\n",
        "ax.set_title('Training and Validation Loss Over Epochs')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "ax.legend()\n",
        "save_plot_as_image(fig, \"loss_plot.png\")\n",
        "pdf.image(os.path.join(output_dir, \"loss_plot.png\"), x=None, y=None, w=190, h=100)\n",
        "\n",
        "pdf_output_path = os.path.join(output_dir, \"glioma_grading_report.pdf\")\n",
        "pdf.output(pdf_output_path)\n",
        "print(f\"Report generated and saved to {pdf_output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
